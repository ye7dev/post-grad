# 3. 통계적 실험과 유의성 검정

- 용어
    - treatment: 어떤 대상에 주어지는 특별한 환경이나 조건
        - 처리 평균은 실험이나 연구에서 각 처리 그룹(또는 요인 수준) 내의 데이터 포인트들의 평균을 의미합니다. 각 그룹의 데이터를 요약하여 그 그룹의 중심값을 제공합니다.
    - test statistic(검정 통계량): 처리 효과를 측정하기 위한 지표
    - hypothesis test = significance test : 관찰된 효과가 우연에 의한 것인지 여부를 알아내는 방법
    - null hypothesis(귀무 가설): 우연 때문이라는 가설 (영가설)
        - 우리가 관찰한 효과가 특벼한 것이 아니고 우연에 의해 발생한 것이라는 개념을 구체화하는 논리적 구조
    - alternative hypothesis(대립 가설): 귀무가설과의 대조(증명하고자 하는 가설)
    - 가설 검정: 귀무 가설이 사실이라고 가정하고, 영모형(null model, 확률 모형(probability model))을 생성하여 관찰한 효과가 해당 모델로부터 합리적으로 나올 수 있는 결과인지를 검증하는 것이다
        - 관찰된 효과가 귀무가설 모형에 대한 무작위 변이의 범위 내에 있는지 결정하는 데 사용
    - one-way test: 한 방향으로만 우연히 일어날 확률을 계산하는 가설검정
    - two-way test: 양방향으로 우연히 일어날 확률을 계산하는 가설 검정
    - permutation test(순열 검정): 두 개 이상의 표본을 함께 결합하여(섞은 뒤) 관측값들을 무작위로(또는 전부를) 재표본으로 추출하는 과정(임의화검정, 임의순열검정, 정확검정)
    - p-value: 귀무가설을 구체화한 기회 모델이 주어졌을 때, 관측된 결과와 같이 특이하거나 극단적인 결과를 얻을 확률
        - 귀무가설로부터 나올 수 있는 결과가 관찰된 결과만큼 극단적으로 나타날 확률
    - alpha: 실제 결과가 통계적으로 의미 있는 것으로 간주되기 위해, 우연에 의한 결과가 능가해야 하는 비정상적인 가능성의 임계 확률
        - 귀무가설 모델에서 ‘비정상’이라고 판단할 임계값
    - 제 1종 오류: 우연에 의한 효과를 실제 효과라고 잘못 결론 내리는 것
        - 암이 아닌데 암이라고 진단. false positive (귀무가설: 암이 아니다)
        - 어떤 효과가 통계적으로 유의미하다고 잘못된 결론을 ㄴ ㅐ린다
    - 제 2종 오류: 실제 효과를 우연에 의한 효과라고 잘못 결론 내리는 것
        - 암인데 암이 아니라고 진단. false negative (귀무가설: 암이 아니다)
    - 검정통계량(test statistic): 관심의 차이 또는 효과에 대한 측정 지표
    - t-statistic: 평균과 같이 표준화된 형태의 일반적인 검정 통계량
    - t-distribution: 관측된 t 통계량을 비교할 수 있는, (귀무가설에서 파생된) 기준 분포
    - 거짓 발견 비율 (False Discovery Rate, FDR): 다중검정에서 1종 오류가 발생하는 비율
    - 알파 인플레이션(alpha inflation): 1종 오류를 만들 확률인 알파가 더 많은 테스트를 수행할 수록 증가하는 다중검정 현상
    - p값 조정: 동일한 데이터에 대해 다중검정을 수행하는 경우 필요
    - overfitting(과적합): 잡음까지 피팅
    - pairwise comparison (쌍별 비교): 여러 그룹 중 두 그룹 간의 (예를 들면 평균에 대한) 가설 검정
    - omnibus test(총괄 검정): 여러 그룹 평균들의 전체 분산에 관한 단일 가설 검정
    - 분산분해(decomposition of variance): 구성 요소 분리. 예를 들면 전체 평균, 처리 평균, 잔차 오차로부터 개별 값들에 대한 기여
    - F-statistic: 그룹 평균 간의 차이가 랜덤 모델에서 예상되는 것에서 벗어나는 정도를 측정하는 표준화된 통계량
    - SS(sum of squares): 어떤 평균으로부터의 편차들의 제곱합
    - 카이제곱통계량(chi-square statistics): 기댓값으로부터 어떤 관찰값까지의 거리를 나타내는 측정치
    - 기댓값(expectation): 어떤 가정(보통 귀무가설)로부터 데이터가 발생할 때, 그에 대해 기대하는 정도
    - d.f(degree of freedom): 자유도
    - 효과크기(effect size): ‘클릭률의 20% 향상’과 같이 통계 검정을 통해 판단할 수 있는 효과의 최소 크기
    - 검정력(power): 주어진 표본크기로 주어진 효과 크기를 알아낼 확률
    - 유의수준(significant level): 검증 시 사용할 통계 유의수준
- 통계적 추론이라는 파이프라인
    - 가설 수립 → 실험 설계 → 데이터 수집 → 추론 및 결론 도출
    - 추론: 제한된 데이터로 주어진 실험 결과를 더 큰 과정(모집단)에 적용하려는 의도 반영

### 3.1 A/B 검정

- 두 가지 처리 방법(제품, 절차) 중 어느 한 쪽이 다른 쪽보다 우월하다는 것을 입증
    - 실험군을 두 그룹으로 나눔 - 대조군(control group) vs. 처리군(treatement group)
    - 가설: 새로운 처리 방법을 적용하는 것이 대조군보다 더 낫다
- 결과를 쉽게 측정 가능
    - 웹 디자인, 마케팅에서 일반적으로 사용
    - 예
        - 두 가지 가격을 검정하여 더 많은 순이익을 산출하는 쪽을 결정
        - 두 개의 인터넷 뉴스 제목을 검정하여 더 많은 클릭을 생성하는 쪽을 결정
        - 두 개의 인터넷 광고를 검정하여 어느 것이 더 높은 전환율을 얻을지 판단
- 처리군 간의 차이
    - 피실험자(subject)가 어떤 특정 처리에 무작위로 할당됨
    - 다른 처리의 효과
    - 어떤 대상이 어떤 처리에 배정될지에 대한 경우의 수
        - 무작위로 배정한 결과 자연스럽게 더 좋은 결과를 보이는 대상들이 A 또는 B 한 쪽에 집중됨
- 검정통계량
    - 그룹 A, 그룹 B를 비교하는 데 사용 - 일반적으로는 이진 변수 → 2x2 표로 요약 가능
        - 예-클릭 유무, 구매 유무, 스팸 유무
    - 측정 지표가 연속형 변수(구매액, 수익)인지 횟수인지(입원 일수, 방문한 페이지 수)
    - 주의
        - default 분석이 늘 유용한 것은 아니다
        - 예: 페이지 뷰당 수익에 대해 평균, 표준편차를 구한 경우
            - 데이터는 적은 수의 높은 값(전환이 있는 페이지 뷰), 많은 수의 0(전환이 없는 페이지 뷰)로 구성
            - 그래서 표준편차가 크게 나와서 수익이 음수가 될 수 있다고 제안한다면 (평균 - 표준편차 < 0) 유용한 정보가 아님
            - 이런 경우는 평균절대편차가 차라리 표준편차보다 합리적이라고 볼수도 있다
- 대조군은 왜 필요할까?
    - 처리 외에 모든 다른 것들은 동일하다는 보장이 필요
    - blind study: 피실험자가 처리 A나 B 중 어느 것을 받고 있는지 알지 못하도록 하는 연구 방식
    - double blind study: 조사자와 진행자(예-의사, 간호사) 모두가 어떤 대상이 어떤 처리를 받았는지 모르게 하는 연구
    - 웹 환경에서의 실험
        - 처리 조건: 웹페이지 디자인, 제품의 가격, 헤드라인의 어감 등
        - 대상: 웹 페이지 방문자
        - 측정 결과: 클릭 수, 구매 수, 방문 기간, 방문한 페이지 수, 특정 페이지 방문 여부 등
    - 실험을 수행한 뒤 나중에 검정통계량을 선택하면 연구자 편향에 빠짐
- 왜 하필 A/B?
    - 추가적인 처리가 포함되는 경우도 있음
        - 피실험자를 대상으로 반복 측정을 하는 경우
        - 제약회사의 임상 실험과 같이 대상이 매우 귀하고 비용이 비싸며 측정에 많은 시간이 필요할 경우, 실험을 중간에 중단하고 결론을 얻을 수 있는 장치를 마련해두고 실험을 설계
    - 데이터 과학자들의 관심은 전통적 의미의 통계적 실험 설계(예-가격 차이가 통계적으로 유의한가?)보다는
        - 가능한 여러 가격 중에서 가장 좋은 가격은 얼마일까? 등에 관심
        - multi-armed bandit과 같은 새로운 유형의 실험 설계가 필요

### 3.2 가설 검정

<aside>
<img src="https://www.notion.so/icons/checkmark_gray.svg" alt="https://www.notion.so/icons/checkmark_gray.svg" width="40px" /> 인간은 실제로 우연히 발생한 일이라도 그것이 흔하지 않다면, 그것에 뭔가 의미가 있을 것이라고 해석하는 경향을 가지고 있다. 그러므로 실험에서 얻은 그룹 간의 차이가 무작위로 얻을 수 있는 합리적인 수준과는 극단적으로 다르다는 증거가 필요하다.

</aside>

- 왜 굳이 가설을 세워야 할까?
    - 임의성을 과소평가하려는 인간의 경향
    - 무작위 사건을 어떤 중요한 의미가 있는 패턴을 갖는 것으로 오해하는 경향
- 통계적 가설 검정
    - 연구자가 랜덤하게 우연히 일어난 일에 속지 않도록 보호하기 위한 방법으로 개발
    - 적절하게 설계된 A/B 검정 → A, B 데이터 수집 → A, B 사이의 관찰된 차이가 다음 원인들로 설명될 수 있도록
        - 우연한 대상 선정
        - A와 B의 진정한 차이
- 귀무가설
    - 그룹들이 보이는 결과는 서로 동일하며, 그룹 간의 차이는 우연에 의한 결과라는 기본 가정
        
        → 이게 틀렸다는 걸 입증해서 그룹 간의 차이가 우연이 아니라는 것을 보여주는 것이 모두의 희망 
        
    - 재표본추출 순열 검정 (permutation test)
        - A와 B 그룹의 결과를 서로 섞어서 비슷한 크기의 그룹들을 반복적으로 만들기
            - 그룹 A, B가 동등하고 상호 교환이 가능하다는 귀무가설을 구현하는 것 = 귀무모델
        - 관찰된 차이를 각 경우에서 발생되는 차이와 비교했을 때 얼마나 극단적인지 관찰
            - **통계량 계산**
                - 각 반복마다 새로운 그룹 A’와 B’에서 관심 있는 통계량(예: 평균 차이)을 계산합니다
                - 예를 들어, 각 반복마다 새로운 그룹 A’와 B’의 평균 차이를 계산합니다.
            - **분포 생성**
                - 반복적으로 계산된 통계량(평균 차이 등)의 분포를 만듭니다.
            - **관찰된 차이와 비교**
                - 실제 데이터에서 관찰된 그룹 A와 그룹 B의 통계량(예: 실제 평균 차이)을 계산합니다
                    - 관찰된 차이가 반복적으로 생성된 분포에서 얼마나 극단적인지 확인합니다.
                    - 관찰된 차이가 분포의 극단적인 부분(예: 상위 5% 또는 하위 5%)에 속하면, 이는 귀무가설을 기각할 근거가 됩니다.
    - 대립가설
        - 귀무가설과 대립가설이 모든 가능성을 설명할 수 있어야 한다
- 일원/이원 가설 검정
    - 방향성을 고려한(단방향) 대립 가설이 필요한 경우
        - A/B 검정을 통해 기본으로 사용하던 옵션 A와 비교하여 새 옵션 B가 어떤지 검증
        - 새 옵션이 완벽히 더 나은 것으로 입증되지 않는 이상, 기본 옵션을 계속 사용한다는 게 가정
            - default 값이 있는 상황
        - B를 선호하는 방향으로 우연이 의해 속지 않도록 검정
            - 그 반대 방향으로 우연에 의해 속는 경우는 없음. A는 이미 잘 쓰고 있었으니.
        - 대립 가설: B는 A보다 낫다
        - 일원(한쪽 꼬리) 가설 검정
            - 우연에 의한 극단적인 결과에 대해 한 방향 만을 고려하여 p 값을 계산
    - 어느 쪽으로도 속지 않도록 양방향 가설 검정이 필요한 경우
        - A는 B와 다르며 더 크거나 더 작을 수 있음
        - 이원(양쪽 꼬리) 가설 검정
            - 우연에 의한 극단적인 결과가 양쪽에서 나타날 p 값을 계산
        - 일원 가설 검정에 비해 보수적
    - p 값의 정확성이 그리 중요하지 않은 데이터 사이언스에서는 그렇게 중요하지 않다

### 3.3 재표본추출

- 랜덤한 변동성을 알아보자는 일반적인 목표를 가지고, 관찰된 데이터의 값에서 표본을 반복적으로 추출하는 것
- 두 가지 유형
    - 부트스트랩: 추정의 신뢰성을 평가하는 데 사용
    - 순열검정: 두 개 이상의 그룹과 관련된 가설을 검증
- 순열 검정
    - 두 개 이상의 sample(group, A/B)가 관여
    - permute: 집합에서 값들의 순서를 변경
    1. 서로 다른 그룹들의 결과를 하나로 합침 
        - 그룹들에 적용된 처리의 결과가 다르지 않다는 귀무가설을 논리적으로 구체화
    2. 결합된 데이터를 잘 섞은 후, 그룹 A와 동일한 크기의 표본을 무작위로(비복원) 추출
        - 이제 여기에는 서로 다른 그룹의 부분 데이터를 포함
    3. 나머지 데이터에서 그룹 B와 동일한 크기의 샘플을 무작위로 비복원 추출
    4. C, D 등의 그룹에 대해서도 동일한 작업 수행 
        - 여기까지가 원본 표본의 크기를 반영하는 재표본 수집 절차
    5. 원래 샘플(그룹 비율의 차이라던가) 에 대해 구한 통계량 또는 추정치를, 지금 추출한 재표본에 대해 모두 다시 계산하고 기록 
        - 한 번의 순열 반복으로 하나의 결과 (이 하나의 결과는 그룹 간의 차이등을 담고 있음)
    6. 앞선 단계들을 R번 반복하여 검정 통계량의 순열 분포를 얻는다 
        - R개의 데이터에 대해 히스토그램을 그린다
    7. 원래 샘플에서 관찰된 차이가 순열분포 안에 있다면 우연히 일어날 수 있는 범위 안에 있는 것 
        - 그게 아니면 통계적으로 유의미한 차이
- web stickiness
    - 두 가지 웹 디자인 → 어느 쪽이 더 나은 판매효과?
    - 판매되는 서비스의 특성: 고가, 판매 빈도가 낮고, 판매 주기가 상당히 길다
        
        → 매출 데이터를 충분히 얻는 데는 너무 오랜 시간이 걸림 
        
    - 서비스 상세 설명하는 내부 페이지의 이용을 대리변수(proxy variable)로 사용해서 결과 측정
        - 가능한 대리 변수: 페이지클릭 수, 페이지 머문 시간 → 평균 세션 시간
        - 목적이 한정되어 있는 페이지라 방문객 수가 그리 많지 안흠
    - 구글 애널리틱스의 한계
        - 평균 방문 시간 측정을 위해 많이 사용하지만, 마지막으로 방문한 세션 시간을측정할 수는 없음
        - 사용자가 마지막 세션에서 어떤 행동(클릭, 스크롤)을 하지 않는 한 마지막 방문 페이지 세션을 0으로 기록함
            - 페이지가 단일이라서 내릴게 없는 경우에도 마찬가지 → 해당 세션 정보를 포함하기 위해서는 추가적인 처리 필요
    - 결과적으로 얻은 데이터: 두 가지 서로 다른 디자인에 대해 총 36세션, 페이지 A는 21, 페이지 B는 15세션이 기록됨
        - 평균 세션 시간으로는 B 그룹에서 A 그룹보다 약 36초 더 길게 나왔는데, 이것이 우연인지 통계적으로 유의미한지 보려면 순열 검정(permutation test) 해야
            
            ![Untitled](Untitled%2012.png)
            
        - permutation한 뒤 1000번 얻은 그룹 차이를 히스토그램으로 그린 뒤, 원래 그룹 차이를 분포 위에 선으로 표시하면
            
            ![Untitled](Untitled%2013.png)
            
            - 수직선이 그려진 위치(원래 샘플에서의 그룹 차이)가 순열 분포 안에 위치하므로 우연히 일어날 수 있는 범위 안에 있는 것
                - 특히 우연히 나눈 그룹 차이가 원래 차이를 넘을 확률은 12%가 넘음
                
                = 통계적으로 유의하지 않다 
                
- 전체 및 부트스트랩 순열 검정
    - 랜덤 셔플링 절차를 부르는 다른 말: random permutation test, randomization test
    - Two variates of permutation test
        - Exhaustive permutation test(전체 순열 검정)
            - 데이터를 무작위로 섞고 나누는 대신, 실제로 나눌 수 있는 모든 가능한 조합을 찾는다
                - 검정통계량이 R개만 나오는게 아니라 원소수 factorial 개가 나올 수 있음
            - 샘플 크기가 비교적 작을 때 실용적
            - 셔플링 많이 반복할 수록 random permutation test 결과는 exhaustive permutation test의 결과와 유사하게 근접
            - exact test(정확검정)이라고도 부름
                - 영모형이 어떤 유의수준 이상으로 더 유의미하다라는 식의 다소 애매한 결론이 아닌, 좀 더 정확한 결론을 보장하는 통계적 속성 때문에
                - 전체 순열 검정은 가능한 모든 재배열을 고려하기 때문에, 귀무가설 하에서 검정 통계량의 실제 분포를 완전히 반영합니다. 이는 모든 가능한 결과를 포함하므로, 통계량의 모든 잠재적 값을 고려하여 p-값을 계산할 수 있습니다. 따라서, 이 방법은 근사값이 아닌 정확한 p-값을 제공합니다.
        - Bootstrap permutation test(부트스트랩 순열검정)
            - random permutation test의 [2-3단계](3%20%E1%84%90%E1%85%A9%E1%86%BC%E1%84%80%E1%85%A8%E1%84%8C%E1%85%A5%E1%86%A8%20%E1%84%89%E1%85%B5%E1%86%AF%E1%84%92%E1%85%A5%E1%86%B7%E1%84%80%E1%85%AA%20%E1%84%8B%E1%85%B2%E1%84%8B%E1%85%B4%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A5%E1%86%B7%E1%84%8C%E1%85%A5%E1%86%BC%20c7f44af798e3466caa35825322ffd5b0.md)에서 비복원으로 하던 것을 복원 추출로 수행
            - 모집단에서 개체를 선택할 때, 개체가 처리군에 할당될 때도 임의성을 보장
- permutation test & data science
    - permutation test: 랜덤한 변이(데이터 재배열)가 어떤 역할을 하는지 알아보기 위해 사용되는 휴리스틱(경험적)한 절차이다
    - 데이터가 숫자, 이진인 경우 모두 가능
    - 샘플 크기가 같아도 달라도 가능
    - 데이터가 정규분포를 따라야 한다는 가정도 필요 없음
    

### 3.4 통계적 유의성과 p 값 (🚨)

- 통계적 유의성: 통계학자가 자신의 실험 결과가 우연히 일어난 것인지, 우연히 일어날 수 없는 극단적인 것인지를 판단하는 방법
    - 결과가 우연히 벌어질 수 있는 변동성의 바깥에 존재하면 통계적으로 유의한 것
- 예-웹 테스트의 결과
    
    
    | 결과 | 가격A | 가격B |
    | --- | --- | --- |
    | 전환 | 200 | 182 |
    | 전환되지 않음 | 23,539 | 22,406 |
    - 가격 A: 가격 B에 비해 약 5% 정도 우수한 결과
        - 가격A: 200/(23539 + 200) = 0.8425%
        - 가격B: 182/(22406+182) = 0.8057%
        - diff: 약 0.0368%
    - 전체 데이터 개수는 46,327
        - 빅데이터라고도 볼 수 있어서 통계성 유의성 검정이 필요 없다고 생각하기 쉬움
            - 주로 작은 표본에서 표본의 변동성을 설명하기 위해 통계적 유의성 검정을 사용하기 때문에
        - 근데 전환율이 너무 낮아서 - 두 가격에서 모두 1% 미만- 실제 필요한 표본 크기를 결정하는 데 매우 중요한 전환 횟수는 정작 200개 정도에 불과
    - resampling 절차를 사용하면 가격 A, B 간의 전환 차이가 우연에 의한 것인지 검정 가능
        - 우연에 의한 차이: 귀무가설(두 전환율 사이에 차이가 없다)의 확률 모형을 가지고 생성한 데이터의 랜덤 변이
    - 🍱 두 가격이 동일한 전환율을 공유하는지, 이 랜덤 변이가 5%만큼의 차이를 만들어낼 수 있는지 확인하기 (실험 및 결과)
        1. 0과 1이 적힌 카드를 박스에 넣는다 
            - 전체 전환율은 (200 +182) / (23,529 + 22,406 + 200 +182) = 0.8246%
            - 0은 23,529 + 22,406 = 45945개
            - 1은 382개
        2. 크기 23,739 (가격 A)의 표본을 섞어서 뽑고 그 중 1이 몇 개인지 기록
            - 23739 = 23529 + 200
        3. 나머지 22,588 (가격 B)에서의 1의 수를 기록 
        4. 2,3에서 1의 비율 차이를 기록 
            - x/23739 - y/22,588
            - [x]  abs? nope
        5. 2~4 단계를 반복
        6. 이 차이가 얼마나 자주 0.0368(원래 갖고 있는 데이터에서 A, B 사이의 전환율 차이)보다 커지는가?
        - 결과 그래프 및 해석
            
            ![Untitled](Untitled%2014.png)
            
            - 관측차이가 검정통계량 분포 내에 존재하므로 랜덤 변이의 범위 내에 있다. 귀무가설 유지
            - 

### p값 ❤️‍🔥

- 그래프를 눈으로 보는 것보다 통계적 유의성을 정확히 측정하기 위한 지표가 필요
    - 확률모형이 관측된 결과보다 더 극단적인 결과를 생성하는 빈도
    - permutation test로 얻은 결과 중에서 관찰된 차이와 같거나 더 큰 차이를 보이는 경우의 비율로 추정
        
        `np.mean([diff > obs_pct_diff for diff in perm_diffs])`
        
    - 해석-예: p값이 0.308
        - 우연히 얻은 결과의 30% 정도가 관측된 차이와 비슷한 정도로 예외적인 결과를 얻을 것으로 기대
- 위의 전환율 문제에서는 binary 변수라서 귀무가설이 이항 분포를 따른다 → p값 근사 가능
    
    `prop.test(x=c(200, 182), n=c(23739, 22588), alternative='greater')`
    
    - 집단의 비율을 비교하여 이들 비율 간의 차이가 통계적으로 유의미한지 여부를 검정하는 데 사용 (집단은 2개 이상도 가능)
    - 결과 해석
        
        ![Untitled](Untitled%2015.png)
        
        - p값: 0.3498
        - 다른 값
            
            •	**카이제곱 통계량**: 비율의 동질성을 검정하기 위한 카이제곱 값.
            
            •	**자유도**: 검정에 사용된 자유도.
            
            •	**p-값**: 귀무가설을 기각할지 여부를 결정하는 데 사용하는 p-값.
            
            •	**95% 신뢰구간**: 각 그룹의 비율에 대한 신뢰구간.
            
            •	**샘플 비율**: 각 그룹의 비율.
            
- 유의수준
    - 어떤 결과가 우연히 발생한 것인지 진짜 특별한 것인지를 결정하기 위해…
        - 우연히 얻은 결과(귀무가설) 결과의 몇 퍼센트(임계값)보다 더 극단적인 결과이면 특별하다고 간주
            - 몇 퍼센트 = 임계값 = alpha = 유의수준
            - 주로 5%, 1% 많이 사용됨
            - p-값이 유의수준보다 작으면 귀무가설을 기각하고 두 변수 간에 통계적으로 유의미한 연관성이 있다고 결론
        - 우연히 일어날 확률은 무엇인가 ≠ 랜덤 모델이 주어졌을 때 극단적인 결과가 나올 확률은 어느 정도인가?
            - 랜덤 모델의 적합도에 관해 역으로 추적
    - p값에 대한 논란
        - 유의미한 p 값이 나올 때까지 온갖 가설검정 수행..
            - 그들이 p값을 통해 전달하고자 하는 의미: 결과가 우연에서 비롯될 확률
            - 더 낮은 p값으로 뭔가를 증명했다고 결론을 내리고 싶어함
        - 실제 p값이 나타내는 것
            - **랜덤 모델이 주어졌을 때, 그 결과가 관찰된 결과보다 더 극단적일 확률**
            - p값에 관한 6가지 원칙
                1. p값은 이 데이터가 특정 통계 모델과 얼마나 상반되는지 나타낼 수 있다
                2. p값은 연구 가설이 사실일 확률이나 데이터가 랜덤하게 생성되었을 확률을 측정하는 것이 아니다
                3. 과학적 결론, 비즈니스나 정책 결정은 p값이 특정 임곗값을 통과하는지 여부를 기준으로 해서는 안된다
                4. 적절한 추론을 위해서는 완전한 보고와 투명성이 요구된다
                5. p값 또는 통계적 유의성은 효과의 크기나 결과의 중요성을 의미하지 않는다
                6. p값 그 자체는 모델이나 가설에 대한 증거를 측정하기 위한 좋은 지표가 아니다.
        - 실제적인 유의미
            - 의미가 없는 작은 차이라도 표본이 충분히 크면 통계적으로 유의하다는 결과가 나올 수 있음
- 1종 오류 vs. 2종 오류
    - 1종 오류: 우연을 사실이라고 잘못 판단 ↔ 2종 오류: 사실을 우연으로 잘못 판단
    - 2종 오류는 어떤 오류라기 보다 표본크기가 너무 작아서 효과를 알아낼 수 없다고 판단하는 것과 같음
        - p값이 통계적 유의성에 미치지 못하는 경우(5% 초과), 실제 의미는
            - 효과가 아직 입증되지 않았다는 뜻
            - 표본 크기가 더 클 수록 p 값이 더 작아진다 ([그래서](3%20%E1%84%90%E1%85%A9%E1%86%BC%E1%84%80%E1%85%A8%E1%84%8C%E1%85%A5%E1%86%A8%20%E1%84%89%E1%85%B5%E1%86%AF%E1%84%92%E1%85%A5%E1%86%B7%E1%84%80%E1%85%AA%20%E1%84%8B%E1%85%B2%E1%84%8B%E1%85%B4%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A5%E1%86%B7%E1%84%8C%E1%85%A5%E1%86%BC%20c7f44af798e3466caa35825322ffd5b0.md))
    - 유의성검정의 기본 기능은 어쩌다 우연히 일어난 일에 속지 않도록 하는 것 → 보통은 1종 오류를 최소화하도록 가설 설계
- 데이터 과학과 p 값
    - p값의 가치에 대한 논쟁은 다소 학문적
    - 실무에서는 관심 있고 유용한 모델의 결과가 일반적인 랜덤 변이 범위 내에 알고 싶을 때 유용한 측정 지표
    - p값으로만 의사 결정 좌우해서는 안됨 - 정보의 일부일 뿐
        - 어떤 모델의 중간 입력으로 사용하거나, p 값에 따라 어떤 피처를 모델에 포함하거나 제외하기도
- + 나는 왜 이렇게 p 값을 가지고 헷갈려했나
    - 요약
        - 모수적 접근: 특정 분포를 가정하고 그 분포에서 p 값을 계산.
        - 비모수적 접근: 분포 가정 없이 데이터를 재샘플링하여 분포를 만든 뒤 p 값을 계산.
    - 보통 모수적 접근에서 t 통계량 구하는 공식을 배우고, 자유도를 계산하고…어쩌고 저쩌고 해야 해서 library(scipy, t.test)를 사용해야만 하는 것

### 3.5 t 검정

- 다양한 유형의 유의성 검정 방법
    - 아래의 요소에 따라 유형이 달라질 수 있음
        - 테이터가 횟수나 측정값을 포함하는지
        - 표본이 얼마나 큰지
        - 측정 대상이 무엇인지
    - 가장 자주 사용되는 것은 t-test
    - 모든 유의성 검정은 관심 있는 효과를 측정하기 위한 검정통계량을 지정, 관찰된 효과가 정상적인 랜덤 변이의 범위 내에 있는지 여부를 판단
    - resampling test(재표본 검정)에서 데이터의 측도는 큰 문제가 X
        - 데이터로부터 기준(귀무가설)분포를 생성하고, 같은 검정통계량을 그대로 사용하면 됨
- t 검정의 유래
    - 통계적 가설검정이 한창 개발중이던 20,30년대에는 재표본검정을 위해 무작위로 데이터를 수천번 섞는다는 것이 거의 불가능
    - 대신 **순열 분포에 대한 좋은 근사가 t-분포에 기초한 t 검정**이라는 것을 발견
    - 데이터가 수치형인 아주 일반적인 2표본 비교(A/B 검정)에 주로 사용
    - 척도에 상관없이 t 분포를 사용하려면, 표준화된 형태의 검정 통계량을 사용해야 함
        - R이나 파이썬에는 이미 데이터를 표준화해서 표준 t 분포와 비교하는 방법이 구현되어 있음
- 예-귀무가설: 페이지 A에 대한 평균 세션 시간이 페이지 B에 대한 평균 세션 시간보다 작지 않다
    
    `t.test(Time ~ Page, data=session_times, alternative='less')`
    
    - 결과 해석
        
        ![Untitled](Untitled%2016.png)
        
        - alternative = ‘less’로 설정해서 대안 가설
            - 그룹별 평균에 대한 true difference가 0보다 작다 = page A 그룹의 평균이 page B 그룹 평균보다 작다로 설정됨
        - p값 0.1408
            - permutation test를 얻은 p값 0.128과 0.131에 매우 가깝다
- 결론
    - resampling을 설명할 때
        - 데이터가 수치형인지 이진형인지
        - 표본크기가 균형 잡혀 있는지
        - 표본분산이 얼마나 큰지 등
    - 다양한 다른 요인에 대해 걱정하지 않고, 관측된 데이터와 검증할 가설만 가지고 답을 구했다
    - 실무에서는 논문 발표를 준비하는 학자처럼 가설검정과 신뢰구간 분석을 위한 세부 사항 때문에 진땀 흘리는 일은 하지 않는다

### 3.6 다중검정

- 알파 인플레이션
    - X: 20개의 칼럼. predictor variable(independent variable) → Y: 1개의 칼럼. response variable(dependent variable)
    - 1종 오류
        - 유의수준 0.05에서 20번의 일련의 유의성 검정을 수행
        - 20개 중에 적어도 하나의 예측변수에서 통계적으로 유의미한 결과를 (실수로) 초래할 가능성이 꽤 있다
            - 이 확률을 구하는 법: 1-(0.05의 유의수준에서 항상 유의미하지 않다는 올바른 검정결과가 나올 확률을 계산한 결과)
            - 💭한 번의 유의성 검정에서 무의미하다고 정확하게 검정할 확률이 0.95
                - 유의수준 0.05
                    - p-value가 이 값보다 작게 나오면, 귀무가설이 참일 때 관찰된 데이터가 나타날 확률이 매우 낮다는 것을 의미 → 귀무가설 기각
                    - 근데 또 한편으로 유의수준이 0.05라는 것은 귀무가설이 참일 때 잘못 기각할 확률이 5%라는 것을 의미하기도
                        - 제 1종 오류를 범할 최대 허용 확률
                        - 귀무가설이 참일 때 이를 올바르게 유지할 확률 : 1-0.05 = 0.95
                    - **결론이 유의미하다 (p-value ≤ α)**
                        - 귀무가설을 기각하지만, 이 결정이 제1종 오류일 가능성이 α입니다.
                    - **결론이 유의미하지 않다 (p-value > α)**
                        - 귀무가설을 기각하지 않지만, 이 결정이 제2종 오류일 가능성이 있습니다.
            
            → 20번 모두 무의미하다라고 올바른 검정 결과를 보일 화률은 0.95**20 ~= 0.36
            
            →1-(모든 것이 무의미하다는 결론이 나올 확률) = 1 - 0.36 = 0.64
            
        - 데이터마이닝의 오버피팅 문제와도 관련
            - 추가하는 변수가 많을 수록, 더 많은 모델을 사용할수록 뭔가가 우연에 의해 유의미한 것으로 나타날 확률이 커짐
            - 지도학습에서는 이런 위험을 낮추기 위해 holdout datset을 사용해서 학습 단계에서는 보지 못했던 데이터를 통해 모델 평가
- 특정 상황에서 이러한 문제를 다루기 위한 몇 가지 방법
    - 예시 상황
        - 여러 처리군간의 결과를 비교하는 경우 여러 질문
            - A와 B가 다른가?, B와 C가 서로 다른가? A와 C가 서로 다른가?
        - 임상실험의 경우 여러 단계별로 치료 결과를 볼 수 있음
            - 각각의 경우에 여러 질문을 하다보니 각 질문마다 우연에 속을 기회가 증가
    - 통계학의 수정(adjustment) 절차
        - 단일 가설 검정을 할 때보다 통계적 유의성에 대한 기준을 더 엄격하게 설정함으로써 이를 보완
        - 검정횟수에 따라 유의수준을 나누는 방법
        - 각 검정에 대해 더 작은 알파를, 즉 통계적 유의성에 대해 더 엄격한 잣대 적용
    - Bonferroni adjustment
        - 알파를 비교횟수 n으로 나눔
    - [Tukey’s HSD](https://rfriend.tistory.com/132)
        - Honest Significant Difference
        - 여러 그룹의 평균을 비교하는 또 다른 방법
        - 그룹 간의 최대 차이(모든 값을 함께 섞고 원래 그룹과 동일한 크기의 재표본 그룹을 뽑아서 만들어진 그룹 평균 간의 차이)에 적용
        - t 분포를 기반으로 한 벤치마크와 비교
- FDR
    - 원래 주어진 여러 개의 가설 검정들 가운데 하나가 유의미한 효과가 있다고 잘못 판단하는 비율을 나타내는데 사용
    - 데이터 마이닝 분류 문제에서는 클래스 1 예측 내의 missclassification rate를 가리킴
        - 발견(record를 1로 표시)이 거짓일 확률
        - 일반적으로는 대부분이 0이고 1은 흥미롭고 드문 경우를 다룬다
- 중복에 대한 실무의 입장
    - 예측 모델의 경우, 교차타당성 검사(cross-validation)과 holdout 데이터셋 사용을 통해
        - 실제 우연히 발생한 것을 겉보기에 유효한 것처럼 보이도록 잘못된 모델을 만들 위험을 낮춘다
    - 미리 분류되어 있는 holdout set이 없는 다른 절차의 경우, 다음 사항에 의존
        - 데이터를 더 여러번 사용하고 조작할수록 우연이 더 큰 역할을 할 수 있다는 것을 인식
        - resampling과 simulation 결과들을 사용해서 random model의 기준 값을 만들어 관찰된 결과를 비교한다
    - 다중성(다중 비교, 많은 변수, 많은 모델)은 일부가 우연히 유의미하다는 결론을 내릴 위험을 증가시킨다
    - 여러 유의성 검정과 관련된 상황에서는 통계적 수정 절차가 필요하다

### 3.7 자유도

- 표본 데이터에서 계산된 통계량에 적용. 변화가 가능한 값들의 개수
    - 예-10개의 값으로 이루어진 표본에서 평균값을 아고 있다면, 여기에는 9개의 자유도가 있다
        - 표본 9개의 값을 알고 있고, 10개에 대한 평균도 알고 있으면, 10번째 표본값은 정해져 있기 때문
- 많은 확률 분포에 적용되는 자유도 모수는 분포의 모양에 영향을 준다
    - 표본통계량이 전통적인 통계 공식에 맞게 표준화된 경우,
    - 자유도는 표준화된 데이터가 그에 적합한 기준분포에 맞도록 하기 위한 표준화 계산의 일부
- 실무에서의 중요성
    - 유의성 검정에서는 별로 중요하지 않다
        - 공식적인 통계검정은 데이터 과학 분야에서 아주 드물게 사용
        - 실무에서는 데이터 크기가 대개 충분히 크기 때문에, 분모가 n인지 n-1인지가 거의 차이 없다
            - n이 커질 수록 분모에 n을 사용할 때 발생할 수 있는 편향이 사라진다
    - 관련성 있는 영역은 회귀에서 요인변수(범주형 변수)를 사용할 때
        - 완전히 불필요한 예측변수들이 있는 경우 회귀 알고리즘을 사용하기 어렵다
        - 범주형 변수를 이진 지표(더미)로 factoring 할 때 가장 많이 일어난다
            - 예-요일: 일주일에 7일이 있지만, 요일을 지정할 때 자유도는 6개
                - 월~토가 아닌 요일이면 반드시 일요일. vector 길이 6개로 일곱 개의 요일을 표시
                    - 일요일: [0, 0, 0, 0, 0, 0] (기준 범주)
            - 이렇게 하지 않고 일요일까지 포함해서 vector 길이 7개로 표현하면 다중공선성(multicollinearity)오차로 인해 회귀를 실패하게 된다

### 3.8 분산 분석

- A/B 검정 말고 여러 그룹 (A/B/C/D 등)의 수치 데이터를 서로 비교
- 여러 그룹 간의 통계적으로 유의미한 차이를 검정하는 통계적 절차: Analysis of Variance (ANOVA)라고 함
- 전통적인 임의 표본추출 설계를 완전히 구현하기 어려운 경우
    - 예-web stickiness(방문자가 페이지에서 보낸 시간, 단위:초)
        - 네 페이지는 무작위로 전환. 각 방문자는 무작위로 그중 한 곳에 접속
        - 각 페이지에는 5명의 방문자
        - 페이지별 칼럼은 독립적인 데이터 집합
            - 페이지 1의 첫번째 viewer는 페이지 2의 첫번째 viewer와 아무 관련 없음
    - 전통적인 방식: 일부 방문자를 어떤 커다란 모집단에서 무작위로 선택하는 식
    - 데이터 수집 방식: 우리가 선택하는 것이 아니라 방문자가 오는 대로 바로 대상이됨
        - 방문자는 시간대, 요일, 계절, 인터넷 환경, 사용하는 장치 등에 따라 체계적으로 다를 수 있음
        - 잠재적 편향의 요인으로 고려해야
- pair vs. group
    - (기존-다중검정) 개별 페이지 pair 간의 비교
        - 4C2 = 6개의 pair가 나온다
        - 그러나 한 쌍씩 비교하는 횟수가 증가할 수록 우연히 일어난 일에 속을 가능성이 커진다
    - (new-총괄 검정) 모든 페이지가 동일한 기본적인 stickiness를 갖는가?
        - 페이지들 사이의 차이는 우연에 의한 것인가?
        - 원래 4개의 페이지에서 측정된 세션 시간 역시 무작위로 할당된 것인가?
        - ANOVA
- ANOVA의 토대가 되는 resampling 과정
    1. 모든 데이터를 한 곳에 모은다
    2. 5개의 값을 갖는 4개의 resampling을 섞어서 추출한다 (한 칼럼 당 5 row였으니까)
    3. 각 그룹의 평균을 기록한다 - 그룹별 평균 (페이지가 4개라 4 그룹)
    4. 네 그룹 평균 사이의 분산을 기록한다 - 그룹간 분산 (값 1개)
    5. 2~4단계를 여러 번 반복한다 (예를 들면 1000번)
    - 이 시뮬레이션을 통해 얻은 결과들에서 계산된 분산이 실제로 관찰된 변화(실제 데이터에서 그룹 간 분산)보다 큰 경우가 얼마나 자주 발생하는지를 계산합니다. 이 빈도가 바로 p 값
- R package - `lmPerm > aovp`
    - 순열 테스트(permulation test)를 사용하여 분산분석(ANOVA)을 수행하는 함수
        - permutation test
            - 데이터를 여러 번 무작위로 섞어 분석하여 얻은 결과와 실제 데이터를 비교하는 방식
            - 비모수적 방법으로, 데이터의 분포에 대한 가정 없이 유의성을 평가할 수 있는 장점
                - 비모수적 접근(Non-parametric approach)
                    - 통계 분석에서 데이터의 분포에 대한 특정한 가정을 하지 않고 사용하는 방법
                        - 데이터가 정규분포를 따른다거나 특정 분포를 따른다는 가정을 하지 않습니다.
                            - 데이터가 비대칭이거나 이상치(outlier)가 존재할 때 유리
                        - 순위 기반 분석 - 데이터의 순서(rank)나 위치를 이용해 통계적 유의성을 평가
        - p 값을 통해 모델의 유의성을 평가
    - 결과 해석
        
        ![Untitled](Untitled%2017.png)
        
        - Pr(Prob) 값이 p 값 : 0.07611
            - 동일한 기본 stickiness를 감안할 때 = 네 페이지 사이의 세션 시간 차이가 없다고 가정할 때
            - 네 페이지 사이의 응답률이 = 네 페이지 사이의 세션 시간이
            - 9.3%의 확률로 실제 관측된 것과 달라지는 경우가 우연히 발생할 수 있다 = 실제 관측된 분산처럼 달라지는 경우가 우연에 의해 발생할 확률이 9.3%
            - 요약하면, 세션 시간의 차이가 없다고 가정해도
                - 9.3%의 확률로 우연에 의해
                - 실제 데이터처럼 차이가 나는 상황이 발생할 수 있다
            - 보통 5%를 유의수준으로 잡으니까 통계적으로 유의미하다고 보기 어려움
        - Iter
            - permutation test에서 수행한 반복횟수
- pandas로 구하는 경우 중간 과정을 더 잘 볼 수 있음
    1. 아래의 과정을 R번 반복한다 → R개의 통계량 얻음 
        1. 주어진 dataframe에서 response variable(Y)에 해당하는 칼럼만 섞는다
        2. predictor variable(X) 값을 기준으로 그룹을 나눈다 
        3. 그룹별 평균을 구한 뒤, 그룹 간 분산을 구한다 → 통계량 1개 나옴 
    2. R개의 통계량 중, 실제 관측된 통계량(variance)보다 큰 값이

### F 통계량 (모수적 접근) 🏋️‍♀️

- 두 그룹의 평균을 비교하기 위해 permutation 대신 t-test를 사용할 수 있는 것처럼 F 통계량을 기반으로 한 ANOVA 통계 검정도 있음
- F 통계량은 residual error(잔차 오차)로 인한 분산과 그룹 평균(처리 효과)의 분산에 대한 비율을 기초로 함
    - 이 비율이 높을 수록 통계적으로 유의미
    - 데이터가 정규분포를 따를 경우, F 통계량은 특정 분포를 따르게 되어 있어서, 이를 토대로 p 값을 계산할 수 있음
    - 여기도 모수적 접근이라 라이브러리 사용한다
- aov 함수
    - 결과 해석
        
        ![Untitled](Untitled%2018.png)
        
        - Df: 자유도
            - 처리 방법에 대한 평균의 자유도 (Page row df) = 3
                - 3개의 평균과 함께 총 평균이 정해지면, 나머지 평균은 달라질 수 없다
                - 데이터에서 그룹 개수 -1이지 않을까
            - 잔차의 자유도 = 16
                - 20개 관측값 중에 16개는 총 평균과 처리 평균이 정해지면 달라질 수 있음
            - 추가 설명
                - **자유도 결정**:
                    - **처리 자유도**: 그룹 수 - 1
                    - **오차 자유도**: 총 관측값 수 - 그룹 수
        - Sum Sq: 제곱합
            - 총평균에 대한 제곱합 : Page 데이터의 총 평균을 구한 뒤, 0에서부터 총 평균까지의 거리를 구하고, 제곱한 다음, 관측 수(20) 곱한 값.
                - 총 평균에 대한 (제곱합의) 자유도는 정의에 따라 1
                - + chat gpt 설명
                    - 전체 데이터의 변동성을 측정하는 총 변동 (SST)
                    - 모든 관측값이 전체 평균으로부터 얼마나 벗어나는지를 제곱하여 합산
            - 처리 평균에 대한 제곱합은 각 처리 평균(그룹별) 과 총 평균 사이의 편차를 제곱한 값들의 합
                - + chat gpt 설명
                    - 그룹 간 변동 (SSB)
                    - 각 그룹의 평균이 전체 평균에서 얼마나 벗어나는지를 측정하여 그룹 간 차이를 평가
            - 잔차에 대한 제곱합
                - 개별 관측치와 처리 평균(그룹 평균) 차의 제곱합
                - 그룹 내 변동 (Within-Group Sum of Squares, SSW)
            - aov 함수에서의 결과
                - 각 요인이나 잔차의 제곱합으로, 데이터 변동의 총합
                - Page 행의 Sum Sq값이 SSB(그룹 간 변동)에 해당합니다.
                - Residual 행의 Sum Sq 값이 SSW(그룹 내 변동)에 해당합니다.
        - Mean Sq: 평균제곱(평균제곱편차)
            - 제곱합을 해당 자유도로 나눈 값으로, 변동의 평균 크기
            - Page 행의 Mean Sq 값이 그룹 간 평균 제곱
            - Residual 행의 Mean Sq 값이 ****그룹 내 평균 제곱
        - F value: F 통계량
            - MS (처리=그룹=페이지)/ MS(오차=잔차)
                - MS(처리): 그룹 간 평균 차이
                - MS(오차): 각 그룹 내 개별 데이터의 변동성
            - 이 비율에 따라 F 값이 결정되고, 표준 F분포와 비교하여 그룹 평균 간의 차이가 랜덤 변이에서 예상되는 것보다 큰 지 여부를 결정할 수 있다
                - 표준 F 분포와 비교
                    - **기준값과 비교**:
                        - 통계 소프트웨어나 F-분포 표를 사용하여 계산한 F-값과 해당 자유도의 임계값(critical value)을 비교합니다.
                        - p-값을 통해 유의수준(일반적으로 0.05)과 비교합니다.
                    - **결론 도출**
                        - F-값 > 임계값 또는 p-값 < 유의수준이면 그룹 간 차이가 통계적으로 유의미하다고 결론짓습니다.
        - 분산 분해
            - 데이터에서 관측된 값들은 다른 구성 요소의 합으로 생각할 수 있다
            - 데이터 내의 관측 값의 경우 평균, 처리 효과, 잔차 오차로 구분 가능
                - 표 3-3의 좌상단 cell 하나에 대한 분산분해를 해보면
                    1. 총평균(책에 있는 테이블 기준으로-173.75)에서 시작 
                    2. 음수인 처리 효과를 추가(독립변수=웹페이지)
                        - 해당 셀이 속한 첫번째 그룹의 평균은 172
                        - 그룹 평균 172- 총 평균173.75 = -1.75 (페이지 효과)
                            - 그룹 간 변동
                    3. 음수일 수 있는 잔차 오차를 더한다. 
                        - 해당 cell의 데이터포인트 값은 164
                        - 164-그룹평균 172= -8 (잔차 오차)
                            - 그룹 내 변동
            - 총 변동(SST)을 그룹 간 변동(SSB)과 그룹 내 변동(SSW)으로 분해
- 이원 분산 분석
    - session time의 예시는 page 범주 하나만 달라짐 (변하는 요소=그룹)이 하나인 일원 분산분석
    - 주말 대 평일이라는 두번째 요소를 고려한 각 조합에 관한 데이터가 있다고 가정
        - 그룹 A 주말, 그룹 A 평일
        - 그룹 B 주말, 그룹 B 평일…
        
        → 이 때 필요한 것이 이원 ANOVA 
        
    - 상호작용 효과를 확인
        - 총 평균 효과와 처리 효과를 확인한 후
        - 각 그룹의 주말과 평일 데이터를 따로 분리
        - 그 부분 집합들에 대한 평균과 처리 평균 사이의 차이를 찾아봄
- 정리
    - 여러 요인과 효과를 모델링할 수 있는 회귀와 로지스틱 회귀 같은 완전한 통계 모델을 위한 첫 걸음이 ANOVA
    - 여러 그룹의 실험 결과를 분석하기 위한 통계적 절차
    - A/B 검정과 비슷한 절차를 확장하여 그룹 간 전체적인 편차가 우연히 발생할 수 있는 범위 내에 있는 지를 평가하기 위해 사용
    - 그룹 처리, 상호작용 효과, 오차와 관련된 분산의 구성 요소들을 구분하여 유용

### 3.9 카이제곱검정

- 사용 맥락: 예) 웹테스트-단순한 A/B 검정을 너머 동시에 여러 가지 처리를 한 번에 테스트
- 카이제곱검정
    - 횟수 관련 데이터에 주로 사용
    - 예상되는 분포에 얼마나 잘 맞는지 검정
    - 카이제곱통계량: 변수 간 독립성에 대한 귀무가설이 타당한지를 평가하기 위해 r x c 분할표를 함께 사용

### 재표본 추출 방법

- 비모수적 접근법이겠지?
- 분석 대상
    - A, B, C 세 가지 헤드라인
    - 각각 방문자 1000명에 관한 결과가 주어짐
    
    |  | A | B | C |
    | --- | --- | --- | --- |
    | 클릭 O | 14 | 8 | 12 |
    | 클릭 X | 986 | 992 | 988 |
    - 세 헤드라인의 효과가 다른 것 처럼 보임
        - A의 클릭 수는 B의 거의 두 배 정도
- resampling 통해서 클릭률이 우연히 발생할 수 있는 것보다 유의미한 정도로 큰 것인지 검정
    - 클릭의 기대 분포가 필요
    - 귀무가설: 헤드라인 모두가 동일한 클릭률을 갖는다는 가정
- 피어슨 잔차
    - R = (관측값 - 기대값) / root(기댓값)
        - 실제 횟수와 기대한 횟수 사이의 차이를 나타냄
    - 예) 헤드라인 A-클릭 O cell에 대한 R 값을 구해보면
        - 기댓값: 모든 헤드라인에서 동일한 클릭률 (=전체 클릭률 = (14+8+12)/3000 ~= 0.01133)
            - 각 headline 당 1000명에 대한 결과이므로 클릭 기댓값은 0.01133*1000 = 11.33
        - 관측값: 14 (out of 1000)
        - R = (14-11.33) / sqrt(11.33) = 0.793224841214779
- 카이제곱통계량은 피어슨 잔차들의 제곱합
    - 모든 cell에 대해 (관측값-기대값) ** 2 / 기대값
    - 제곱하면서 sqrt 사라짐
- resampling으로 카이제곱통계량이 귀무가설로부터 얻을 수 있는 값보다 크다고 할 수 있는지 검정하는 절차
    1. 34개의 1(클릭 O)과 2966개의 0(클릭 X)가 포함된 array를 만든다
    2. array를 permutation 한 후 1000개씩 세번 가져와서 각각의 1(클릭) 수를 계산한다
    3. 이렇게 얻은 횟수와 기대한 횟수(11.33)의 차이를 (가지고 피어슨 잔차를 구한 뒤) 제곱해서 합산한다 
    4. 2~3단계를 1000번 반복한다 
    5. resampling을 통해 얻은 분포에서 관측값보다 큰 값의 비율을 구한다 (p값)
        - resampling을 통해 얻은 편차의 제곱합이 얼마나 자주 관측값을 초과하는지 체크
- R 라이브러리로 계산 가능
    
    ![Untitled](Untitled%2019.png)
    
    - p-value: 0.4848로 유의 수준인 0.05 보다 훨씬 크기 때문에 얼마든지 귀무가설로부터 얻을 수 있는결과임을 보여준다 = 차이가 통계적으로 유의미하지 않다
- 통계적 이론(모수적 접근법)
    - 점근적(asymptotic) 통계 이론 - 카이제곱통계량의 분포가 카이제곱분포로 근사화될 수 있음을 보여줌
    - 적절한 표준 카이제곱분포는 자유도에 의해 결정
        - 분할표에서 자유도는 (r-1) * (c-1) (r: 행, c:열)
    - 분포 모양: 한쪽으로 기울어져 있고 오른쪽으로 긴 꼬리
    - 카이제곱분포는 카이제곱통계량을 비교할 기준분포(독립성 가정 포함)
        - 관찰된 통계량이 분포의 바깥쪽에 위치할 수록 p 값이 낮아짐
            - resampling해서 얻은 p 값보다 약간 작음. 카이제곱분포가 실제 통계 분포가 아니라 근사치이기 때문
- 피셔의 정확검정
    - 사건 발생 횟수가 매우 낮을 때-5개 이하-는 분포를 이용한 모수적 접근 방법이 resampling test의 좋은 근사치를 제공하기는 어려움
    - 대부분의 통계 소프트웨어는 발생할 수 있는 **모든 조합**(순열)을 실제로 열거하고, 빈도를 집계하고, 관찰된 결과가 얼마나 극단적으로 발생할 수 있는 지를 정확하게 결정하는 절차를 제공
        - 이렇게 얻은 p값은 resampling 방법을 통해 얻은 p 값과 아주 가까움
    - 일부 값이 매우 낮고 다른 값이 상대적으로 매우 높은 경우
        - 전환율 계산에서 1은 적고 0이 매우 많은 것처럼
        - 모든 가능한 순열을 계산하기는 어렵기 때문에, 완전한 정확검정 대신 순열검정을 수행해야 할 수 있음
            - chisq.text 함수에서 `simulate.p.value` parameter
                - 정확 검정 대신 순열 검정을 수행할지 여부. 반복 횟수는 parameter `B` 로 지정
                
                c.f. resampling method comparison
                
                1. Permutation methods use sampling without replacement to test hypotheses of ‘no effect’; - 귀무가설 
                2. Bootstrap methods use sampling with replacement to establish confidence intervals; - 신뢰구간
                3. Monte Carlo methods use repeated sampling from populations with known characteristics to determine how sensitive statistical procedures are to those characteristics - 통계적 절차가 특징에 얼마나 민감한지 
- DS와의 관련성
    - 카이제곱검정이나 피셔의 정확검정은 어떤 효과가 실제인지 아니면 우연인지 알고 싶을 때 사용
        - 고전 통계 응용 분야에서 카이제곱검정의 역할
            - 통계적 유의성 결정. 연구를 논문에 싣기 전에 할 필요가 있음
            - 논문게제를 위해 통계적으로 유의미한 p 값을 찾는 연구에서 널리 사용
    - 그러나 DS에서는 단순히 통계적 유의성을 조사하는 것이 아니라 최적의 처리 방법을 찾는 것
        - 이를 위해서는 멀티암드밴딧 방법이 더 정확한 해결책
    - 웹 실험에서 적합한 표본 크기 반별
        - 클릭률이 매우 낮기 때문에 수천번의 실험에도 불구하고, 집계 비율이 너무 낮아 실험을 통해 확실한 결론을 내리기 어렵다
        - 이 경우 피셔의 정확검정, 카이제곱검정, 기타 검정(?)은 검정렬이나 표본크기를 계산하는데 유용
    - DS에서는 카이제곱검정이나 유사한 재표본추출 시뮬레이션을 필터로 더 많이 사용
        - 어떤 효과나 특징에 대해 기본적인 유의성 검정을 넘어 더 심층적인 분석이 필요할지 여부를 결정
            - 예-공간 통계학에서 공간 데이터가 어떤 특정 영분포를 따르는지 여부
                - 랜덤인 경우보다 특정. 영역에 범죄가 집중되고 있는가?
            - 예-머신러닝에서 자동 특성 선택
                - 특성에 따라 클래스의 분포가 어떤지 조사하고, 특정 클래스의 분포가 랜덤 변이에 비해 비정상적으로 크거나 작은 특성을 알아내는 등에 사용
- (++) stat trek 복습
    
    [https://stattrek.com/chi-square-test/independence](https://stattrek.com/chi-square-test/independence)
    

### 3.10 멀티암드 밴딧 알고리즘

- 전통적인 통계적 접근 방식 < 명시적인 최적화, 더 빠른 의사결정. 웹 테스트를 위해 주로 사용
- 고객이 선택할 수 있는 손잡이가 여러 개인 가상의 슬롯머신
    - 각 손잡이는 각기 다른 수익을 가져다 줌 - 다중 처리 실험에 대한 비유
    - 손잡이: 실험에서 어떤 하나의 처리 (예-웹 테스트에서 헤드라인 A)
    - 수익: 슬롯머신으로 딴 상금에 대한 실험적 비유(예-고객들의 링크 클릭 수)
- 전통적인 A/B 검정의 한계
    - 특정하게 설계된 실험 → 데이터 수집 → 정해진 질문에 대한 답(A or B is better) → 실험 중단 → 결과에 따라 행동
    - 결론을 내리기 어려운 경우
        - 실험 결과를 통해 효과가 있다는 것을 유추할 수 있지만, 그것을 입증할 만한(전통적인 통계 표준을 만족시킬 만한) 크기의 표본이 없는 경우
    - 실험이 끝나기 전에 이미 얻은 결과를 이용하기 시작하는 경우
    - 실험이 끝난 후에 추가적으로 들어오는 데이터를 기반으로 다른 것을 시도
- MAB
    - 둘 이상의 손잡이가 달려 있고, 각 손잡이는 다른 속도로 돈을 지불하는 슬롯머신
        - 각 손잡이는 다른 속도로 돈을 지불한다 = 각 손잡이의 확률 분포(보상의 평균과 분산)이 다르다
            
            ![Untitled](Untitled%2020.png)
            
    - 목표: 가능한 많은 돈을 얻기. 많은 상금이 나오는 손잡이를 빨리 확인하는 것
        - 장애물: 손잡이를 잡아당길 때 총 얼마를 지불할 지 모른다는 것. 손잡이를 당겼을 때 개별적인 결과만 알 수 있음 (승리 or 실패)
    - 어떤 손잡이든지 상금이 모두 같은 금액이라고 가정
        - 손잡이 별로 승리할 확률이 다름
            - 예) 초기 시험 50번 시도에서 얻은 정보 A: 10/50, B:2/50, C:4/50
                - 극단적인 결론 1: A가 최고로 보이니 A만 당기자
                    - A 외의 다른 것들의 확률을 알 수 있는 기회는 놓침
                - 극단적인 결론 2: 모두가 무작위이니까 똑같이 잡아당기자
                    - A 외의 다른 것들의 확률을 알 수 있는 기회를 최대화
                    - 그 과정에서 수익이 낮을 것으로 예상되는 행위를 자주 시도
    - 하이브리드 접근 방식
        - 초기 시험에서 얻은 정보에 따라 A의 우위를 활용하기 위해 A를 더 자주 잡아당기는 것으로 시작하지만, 그렇다고 B와 C를 포기하지는 않는다
        - A에서 성과가 계속 좋으면 B, C를 당길 기회를 A에게 더 줘서 A를 더 자주 잡아당기기
        - C가 좋아지고 A가 나빠지면 A로 가던 기회를 C에게 돌리기
    - 웹 테스트에 적용
        - 손잡이: 웹 페이지 헤드라인, 색상 등
        - 수익: 클릭(승리), or not
        - 초기 시험: 여러 제안을 무작위로 균등하게 나타내기
            - 한 제안이 두각을 보이면 더 자주 노출
- 손잡이별 잡아 당기는 비율을 수정하는 알고리즘을 위한 파라미터는? 언제 어떻게 비율을 수정?
    - 엡실론 그리디 알고리즘 for A/B 검정
        1. 0부터 1 사이의 uniform 분포의 random number 생성
        2. 이 숫자가 0과 epsilon(0과 1 사이의 값으로 아주 작은 값) 사이에 존재하면, 50/50 확률로 동전 뒤집기를 시행 
            1. 그 결과 동전이 앞면이면 제안 A 표시
            2. 그 결과 동전이 뒷면이면 제안 B 표시 
        3. 숫자가 엡실론보다 크면, 지금까지 가장 좋은 결과를 보인 제안을 표시
        - 엡실론 파라미터
            - 1이면 표준 A/B 검정(매 실험마다 A, B를 무작위로 할당) 하는 셈
            - 0이면 greedy algorithm-당장 최상의 즉각적인 옵션을 선택. 더 이상 실험 없이
    - 톰슨의 샘플링
        - 각 단계마다 표본을 추출(손잡이를 당김) → 최고의 손잡이를 선택할 확률을 최대화
        - 연속적인 추출을 통해 얻는 수익을 관찰
        - 베이즈 방식을 사용
            - 베타 분포(베이즈 문제에서 사전 정보를 지정하는 일반적인 메커니즘)사용하여 수익의 일부 사전 분포를 가정
            - 각 추출 정보가 누적되면서 정보가 업데이트 → 다음번에 최고 손잡이를 선택할 확률을 효과적으로 최적화
                - 손잡이마다 독립적인 분포를 갖는다
                    
                    네, 톰슨 샘플링에서는 각 손잡이(슬롯머신)의 보상 분포는 독립적입니다. 즉, 한 손잡이의 보상 결과는 다른 손잡이의 보상 결과에 영향을 미치지 않습니다. 각 손잡이는 고유한 확률 분포를 가지며, 이 분포는 해당 손잡이의 과거 보상 데이터를 기반으로 업데이트됩니다.
                    
        - 추가 설명
            - 예
                
                1.	초기화: 손잡이 A와 B의 성공과 실패 횟수를 0으로 초기화합니다.
                
                A: 성공 0, 실패 0
                
                B: 성공 0, 실패 0
                
                2.	샘플링: 손잡이 A와 B 각각에 대해 베타 분포에서 무작위 샘플을 뽑습니다.
                
                A: 샘플 값 0.6
                
                B: 샘플 값 0.3
                
                3.	손잡이 선택: 샘플 값이 높은 손잡이 A를 선택합니다.
                
                4.	보상 업데이트: 손잡이 A를 당긴 후 보상을 관찰합니다. 예를 들어, 보상을 받았다면 성공 횟수를 증가시킵니다.
                
                A: 성공 1, 실패 0
                
                B: 성공 0, 실패 0
                
                5.	반복: 다음 라운드에서는 다시 각 손잡이에서 샘플링을 하고, 가장 높은 샘플 값을 가진 손잡이를 선택합니다.
                
            - 보상 업데이트 → 샘플링 분포 변경
                
                톰슨 샘플링에서는 보통 베타 분포(Beta distribution)를 사용하여 각 손잡이의 보상을 모델링합니다. 베타 분포는 두 개의 매개변수(α, β)로 정의되며, 여기서 α는 성공 횟수 + 1, β는 실패 횟수 + 1입니다.
                
                **보상 업데이트 과정:**
                
                1.	**보상 관찰**: 손잡이를 당긴 후 보상이 발생했는지 여부를 관찰합니다.
                
                2.	**성공/실패 횟수 업데이트**: 보상이 발생했다면 성공 횟수(α)를 증가시키고, 보상이 발생하지 않았다면 실패 횟수(β)를 증가시킵니다.
                
                **업데이트 후의 샘플링:**
                
                •	각 손잡이에 대해 베타 분포에서 무작위로 샘플을 추출합니다.
                
                •	성공 횟수(α)가 많아질수록, 해당 손잡이의 샘플 값이 높아질 가능성이 커집니다.
                
                •	실패 횟수(β)가 많아질수록, 해당 손잡이의 샘플 값이 낮아질 가능성이 커집니다.
                
                - 구체적인 예
                    
                    ```
                    1.	초기 상태:
                    •	손잡이 A: α = 1, β = 1 (성공 0, 실패 0)
                    •	손잡이 B: α = 1, β = 1 (성공 0, 실패 0)
                    2.	손잡이 A를 선택하여 보상을 받음 (성공):
                    •	손잡이 A: α = 2, β = 1 (성공 1, 실패 0)
                    •	손잡이 B: α = 1, β = 1 (성공 0, 실패 0)
                    3.	다음 샘플링:
                    •	손잡이 A: 베타 분포 Beta(2, 1)에서 샘플 추출
                    •	손잡이 B: 베타 분포 Beta(1, 1)에서 샘플 추출
                    4.	손잡이 B를 선택하여 보상을 받지 못함 (실패):
                    •	손잡이 A: α = 2, β = 1 (성공 1, 실패 0)
                    •	손잡이 B: α = 1, β = 2 (성공 0, 실패 1)
                    5.	다음 샘플링:
                    •	손잡이 A: 베타 분포 Beta(2, 1)에서 샘플 추출
                    •	손잡이 B: 베타 분포 Beta(1, 2)에서 샘플 추출
                    
                    ```
                    
    - ++ medium 글, Bandit algorithms for website optimization에서 MAB 정의, 파이썬 코드, 시뮬레이션 결과 체크
        
        [https://medium.com/udemy-engineering/building-a-multi-armed-bandit-system-from-the-ground-up-a-recommendations-and-ranking-case-study-b598f1f880e1](https://medium.com/udemy-engineering/building-a-multi-armed-bandit-system-from-the-ground-up-a-recommendations-and-ranking-case-study-b598f1f880e1)
        

### 3.11 검정력과 표본 크기

- 웹 테스트 수행 시 처리당 얼마나 많은 노출이 필요한지는 어떻게 결정?
    - 표본크기에 대한 고려 → 가설 검정이 실제로 처리 A와 B의 차이를 밝혀낼 수 있을까?
    - 가설 검정의 결과 p 값은 A와 B 사이에 실제 차이가 있는지에 따라 달라짐
    - 실제 차이가 크면 클 수록 그것을 밝혀낼 가능성도 따라서 커짐
        
        ↔ 차이가 작으면 자을 수록 더 많은 데이터가 필요 
        
- **검정력(power)**
    - 특정 표본 조건(표본 크기, 변이)에서 특정한 효과 크기를 알아낼 수 있는 확률
    - 예-25타석에서 3할 3푼 타자와 2할 타자를 구분할 수 있을 확률이 0.75라고 가정
        - 효과크기: 1할 3푼의 타율 차이(0.330-0.2 = 0.130)
        - 알아낸다=구분한다: 가설 검정을 통해 차이가 없을 것이라는 영가설(귀무가설)을 기각하고 실제 효과가 있다고 결론을 내리는 것
        - 검정력: n=25의 표본 크기에서 0.130효과 크기를 알아낼 수 있는 확률이 0.75
    - 검정력을 결정하는 유인
        - 가설검정에서는 표본 변이, 효과크기, 표본크기, 유의 수준 등을 특정하는데 수많은 통계적 가설과 수식에 말려들기 십상
        - 그러나 이를 목적으로 한 통계 소프트웨어가 있기 때문에 DS에서는 검정력을 구하기 위해 형식적인 절차를 모두 지킬 필요는 거의 없다
        - 다만 데이터 수집을 위해(표본 크기가 어느 정도 될런지) 대충 얼마의 비용이 발생할지 안다면, 데이터를 수집하고도 결론을 내리지 못하는 상황을 피할 수 있음
    - 검정력 추정치를 직관적으로 구하는 방법
        1. 최대한 사전 정보를 이요해서 결과 데이터가 비슷하게 나올 수 있는 가상의 데이터 생성
            - 예: 2할 타자를 위해 20개의 1과 80개의 0이 들어 있는 상자를 생각
            - 예: 웹페이지 방문 시간을 관측한 자료가 담겨 있는 상자를 생각
        2. 첫 표본에서 원하는 효과크기를 더해서 두번째 표본을만든다 
            - 예: 3할 3푼 타자를 생각해서 20+13개의 1과 100-33=67개의 0을 가진 두번째 상자를 생성
            - 예: 웹페이지 초기 방문 시간에 25초를 더한 두번째 상자를 만듦
        3. 각 상자에서 크기 n인 부트스트랩 표본을 추출
        4. 두 부트스트랩 표본에 대해서 permutation test(혹은 수식 기반의 가설 검정)을 진행한 뒤, 통계적으로 유의미한 차이가 있는지 기록 
        5. 3~4단계를 여러번 반복한 후, 얼마나 자주 유의미한 차이가 발견되는지 알아본다. 이 확률ㅇ ㅣ바로 검정력 추정치 
- 검정력 계산의 주 목적: 표본크기가 어느 정도 필요한가 추정
    - 예-기존 광고 vs.  새로운 광고 비교를 위해 노출당 클릭이 발생하는 백분율(클릭률) 조사
        - 이 조사를 위해 얼마나 많은 클릭 수를 수집해야 할까?
            - 50% 정도의 큰 차이에만 관심이 있다면 상대적으로 적은 수의 표본으로도 목표를 이룰 수 있음
            - 그러나 그보다 훨씬 작은 차이에도 관심이 있다면 훨씬 더 큰 표본이 필요
        - 새 광고가 기존 광고에 비해 얼마큼(예-10%) 효과적이어야 하는지, 
        어느 정도 이상 효과적이지 않다면 기존 광고를 계속 쓸지에 대한 기준을 설정
        
        = 효과 크기가 표본의 크기를 좌우 한다 
        
    - 예-현재 클릭률 약 1.1% 수준 vs. 여기서 약 10% 증가한 1.21%를 원한다고 가정
        - 각각 10000의 요소가 들어 있는 두 상자
            - 1.1%의 1이 들어 있는 상자 A(110개의 1, 9890개의 0)
            - 1.21%의 1이 들어 있는 상자 B(121개의 1, 9878개의 0)
        - 각 상자에서 300개씩 뽑은 (=각 광고에 대한 300명의 첫 인상) 결과
            - 상자A: 3개의 1 (out of 300. 297개의 0과 같음)
            - 상자B: 5개의 1
            - 어떤 가설검정을 해도 5개와 3개 차이가 유의미하지 않게 나올 것
                - 이 표본크기(300개)와 효과크기(10% 차이)의 조합은 가설검정을 통해 보이기에는 너무 작다
        - 보고자 하는 차이=효과크기를 1.1%에서 50% 증가한 1.65로 늘리고, 표본크기도 2000개로 늘려서 실험
            - 결과
                - 상자A: 19/2000
                - 상자B: 34/2000
            - 34-19 = 15개의 차이는 여전히 유의성 검정을 해도 유의미하지 않다고 결론 날 것
        - 검정력을 계산하기 위해서는 이러한 과정을 여러 번 반복해야
- 검정력, 필요한 표본크기 계산과 관련된 4가지 중요한 요소
    - 표본크기, 탐지하고자 하는 효과크기, 가설검정을 위한 유의수준, 검정력
    - 이 중 세 가지를 정하면 나머지 하나를 알 수 있다
        - 일반적으로 나머지 하나가 표본크기가 되는 경우가 많다
- 효과 크기(effect size)의 직관적 이해
    - 연구 결과에서 관찰된 차이나 관계의 크기
    - **코헨의 d (Cohen's d)**
        - 두 그룹 간의 평균 차이를 표준편차로 나눠서 표준화된 차이를 제공
        - 예시: 두 그룹의 평균 키 차이를 비교한다고 가정해 봅시다. 만약 그룹 A의 평균 키가 170cm이고 그룹 B의 평균 키가 160cm이며, 표준편차가 5cm라면 코헨의 d는 다음과 같이 계산됩니다:
            - d = (170 - 160) / 5 = 2
        - **해석**: 코헨의 d가 2라면, 이는 두 그룹 간의 키 차이가 매우 크다는 것을 의미합니다.
    - **코헨의 h (Cohen's h)**:
        - 비율 간의 차이를 각변환을 통해 표준화
        - 예시: 두 그룹의 성공률을 비교한다고 가정해 봅시다. 그룹 A의 성공률이 60%이고 그룹 B의 성공률이 40%라면, 코헨의 h는 다음과 같이 계산됩니다:
            
            h = 2 * (arcsin(sqrt(0.6)) - arcsin(sqrt(0.4)))
            
        - **해석**: 코헨의 h가 크면, 두 그룹의 성공률 차이가 큽니다.
    - 직관적 이해
        - 작은 효과 크기 (small effect size): 변화나 차이가 있지만 눈에 띄지 않을 정도로 작음. 예를 들어, 두 약물의 효과 차이가 매우 미미한 경우.
        - 중간 효과 크기 (medium effect size): 어느 정도 눈에 띄는 차이. 예를 들어, 새로운 교육 프로그램이 학생들의 성적을 약간 향상시키는 경우.
        - 큰 효과 크기 (large effect size): 매우 분명한 차이. 예를 들어, 특정 치료법이 환자의 회복률을 크게 향상시키는 경우.
        
- R의 pwr 패키지 이용한 결과
    - 확률 차이가 0.0011 → 0.0054로 관찰하려는 차이가 커지면 필요한 sample size (=n)이 거의 절반으로 줄어든 것을 알 수 있음
        
        ![Untitled](Untitled%2021.png)
        
        - alternative는 왜 greater인가
            - 우리가 명확히 원하는 것은, 알고 싶은 것은, 새 광고를 노출했을 때 클릭률이 ‘증가’ 하느냐이기 때문.
            - 따라서 대립가설=alternative는 greater.
        - power : 80%의 검정력을 원함
- statsmodels 패키지 - `TTestIndPower`
    - 독립 표본 t-검정의 파워(검정력) 분석을 수행하는 데 사용
    - 이 클래스는 두 독립적인 그룹 간의 평균 차이를 검정하기 위해 필요한 샘플 크기, 효과 크기, 유의 수준, 검정력(파워) 등을 계산하는 데 유용
    - 클래스에 속한 메소드 함수들
        - solve_power: 파워 분석을 통해 한 가지 매개변수를 계산합니다. 나머지 매개변수는 알고 있는 값으로 지정합니다.
            - 주어진 효과 크기, 유의 수준, 검정력에서 필요한 샘플 크기를 계산
            - `result = analysis.solve_power(effect_size=effect_size, alpha=0.05, power=0.8, alternative='larger')`
                - effect_size, alpha(유의수준), power 주어진 상태에서 sample size 계산.
                - r에서와 마찬가지로 대립가설은 p1이 더 크다
        - power: 주어진 샘플 크기와 효과 크기에서 검정력을 계산
        - sample_size: 주어진 효과 크기와 검정력에서 필요한 샘플 크기를 계산
- 정리
    - 통계검정을 수행하기 앞서, 어느 정도의 표본 크기가 필요한지 미리 생각할 필요가 있다
    - 알아내고자 하는 효과의 최소 크기를 지정해야 한다
    - 효과크기를 알아내기 위해 요귀되는 확률(검정력)을 지정해야 한다
    - 수행할 가설 검정에 필요한 유의수준을 정해야 한다
    - DS에서는 직관적인 재표본추출 과정(순열, 부트스트랩)을 통해 데이터 분석에서 우연에 의한 변이가 어느 정도까지 영향을 미치는지 측정할 수 있게 되었다.
- ++ 적절한 샘플 사이즈를 설정하는 방법
    
    [http://pmean.com/09/AppropriateSampleSize.html](http://pmean.com/09/AppropriateSampleSize.html)